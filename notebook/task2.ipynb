{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d989ef17-aa53-4a66-a3a1-d171da081194",
   "metadata": {},
   "source": [
    "# AI4Omics Practical Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8083162-16af-4e5d-b4ce-b63a2ce248c9",
   "metadata": {},
   "source": [
    "## Task 2 - Introduction to Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b874ac-0b1b-4f0e-9665-f288d3b0f50d",
   "metadata": {},
   "source": [
    "Before we start, please, execute the following code to be ready for exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cda83-5b3c-41a0-9d5e-535b4760b409",
   "metadata": {},
   "source": [
    "- Import pandas and several scikit-learn modules that will be used in the exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0d704-0340-4d76-8c4b-c7e3069373ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d5a63-bee5-4c43-a9d7-de05466c0b5d",
   "metadata": {},
   "source": [
    "- Define the function `calculate_accuracy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fc791-39e0-43f9-83e0-b66f0fa913c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_train = classifier.predict(X_train)\n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    accuracy_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "    print('Train accuracy:', '{:.3f}'.format(accuracy_train), 'Test accuracy:', '{:.3f}'.format(accuracy_test))\n",
    "    return accuracy_train, accuracy_test, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578fb47-4364-4dae-bfc9-d9478288476c",
   "metadata": {},
   "source": [
    "- Import data and create targets **y**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b467c9-b2e9-4c54-b12f-8eeed45d8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "data = pd.read_csv('../data/colon_cancer.csv', sep=';', index_col='id_sample')\n",
    "print('data', data.shape)\n",
    "y = data['tissue_status']\n",
    "print('y', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e4bcf-7d42-4b1c-b5f7-1a8f4117bd32",
   "metadata": {},
   "source": [
    "## Question 1. Create a dataframe X including all the available features (genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189eadc8-74ab-4cf6-9248-89e345ba0378",
   "metadata": {},
   "source": [
    "The original dataset **data** contains 60 columns with the expression levels of 60 genes and one column `tissue_status` with the sample types (normal or tumoral)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcbfc5-7dba-404c-b295-f866156a5232",
   "metadata": {},
   "source": [
    "- Extract 60 columns corresponding to gene expression levels from **data** to a separate dataframe **X**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c97361-6186-44b4-9676-64b1de064c7f",
   "metadata": {},
   "source": [
    "Hint: you can use one of the methods `select_dtypes('number')` or `drop(columns=['tissue_status'])`. Please check the documentation of pandas for these two methods if you are not familiar with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad134b8c-1953-4ce5-8e43-c504f38a81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data... # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eda8f3-ea01-4a0c-b71c-5534c378a51d",
   "metadata": {},
   "source": [
    "## Question 2. Create train and test datasets with 3/4 and 1/4 of samples respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74640d-f3d6-47da-9259-731ef1d9d6d2",
   "metadata": {},
   "source": [
    "- Create a training dataset **X_train** and a test dataset **X_test** with their corresponding targets **y_train** and **y_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa247287-5d1e-40d8-b493-fb9ef062c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=..., random_state=random_state, stratify=y) # test_size to define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d3759-3cbd-4a04-b90a-c6f3ede0a102",
   "metadata": {},
   "source": [
    "- How many samples contain the obtained train and test datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e9186-8163-4ead-a933-3c9a06b735a0",
   "metadata": {},
   "source": [
    "Hint: you can use `shape` attribute of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e47108-c4f3-4ab0-a84c-9da432606e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train:', X_train..., 'Test:', X_test...) # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264c9c9-6f0f-4adc-9b0c-d73431aaafad",
   "metadata": {},
   "source": [
    "## Question 3. Perform a standardisation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25008b35-805b-4047-b967-1fdefc997320",
   "metadata": {},
   "source": [
    "*Data standardisation* is a typical and often mandatory step in a machine learning pipeline. Data standardisation is a *feature scaling* technique aiming to convert original data, where multiple features can be spanning varying ranges and degrees of magnitude, into a comparable range of values. The data standardisation significantly improves the performance of many machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d03e2-100e-4874-a831-3fda6da4d357",
   "metadata": {},
   "source": [
    "The most common standardisation technique is *Z-score* (or standard score) where the values are centered around the mean with a unit standard deviation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4664df-9141-40fb-bd38-9fdb264a3af5",
   "metadata": {},
   "source": [
    "**Warning!** The calculation of the mean $\\mu$ and the standard deviation $\\sigma$ must be performed **on the training dataset** only. The test dataset should not be used in the calculation. It will be scaled using the values $\\mu$ and $\\sigma$ obtained in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd02e2-c7ae-4584-9f01-32f3e26de564",
   "metadata": {},
   "source": [
    "In `scikit-learn`, data standardisation can be realized with a `StandardScaler` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e25c8-1b77-47ae-a216-ab88e2293d8e",
   "metadata": {},
   "source": [
    "- Execute the following code to calculate $\\mu$ and $\\sigma$ for **X_train** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d16722-78ec-4cf0-b7a3-205bcd9d937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # create a scaler\n",
    "scaler.fit(X_train) # calculate mu and sigma on X_train (only training dataset should be used!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8749d96c-a683-4a71-ae1f-3afd2448e7e6",
   "metadata": {},
   "source": [
    "- Display $\\mu$ (mean) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4aa2d-54da-4d7b-b075-67b1e3b4ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display calculated mu (mean) for each feature\n",
    "print('Mean mu', scaler.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa7ecb-9afa-4f1b-aa65-7d2c95876f5d",
   "metadata": {},
   "source": [
    "- Display $\\sigma$ (standard deviation) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa718747-dd98-4080-b300-4590be8c64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display calculated sigma (standard deviation) for each feature\n",
    "print('Std sigma', scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991afef6-e507-4b2e-95d7-24438d53046c",
   "metadata": {},
   "source": [
    "Now, we can use $\\mu$ and $\\sigma$ calculated from **X_train** dataset to perform a standardisation of both **X_train** and **X_test**. Use the `transform` method of the `scaler`object. As a result, you should obtain two scaled datasets: **X_train_scaled** and **X_test_scaled**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c49906-117a-422f-8598-85716c1e72e7",
   "metadata": {},
   "source": [
    "- Execute the code for **X_train**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415d5c0-32cf-4f4e-9a71-c12230ffedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute\n",
    "X_train_scaled = scaler.transform(X_train) # numpy object\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns) # convert to pandas DataFrame format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46bd313-12e8-48e2-8cdf-b2ebbd425539",
   "metadata": {},
   "source": [
    "- Complete a similar code for **X_test** and execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73010c21-53fc-4034-9d1c-be25b8fa79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_scaled = scaler.transform(...) # to complete\n",
    "\n",
    "# X_test_scaled = pd.DataFrame(X_test_scaled, index=...index, columns=...columns) # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c739474-6d07-4011-9da4-e26b5cfbdfd5",
   "metadata": {},
   "source": [
    "After the standardisation, the mean values of expression levels should be equal to 0 for all genes in **X_train_scaled**, and the standard deviation should be equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c438ad-eab8-44d7-901d-74bcfab8291b",
   "metadata": {},
   "source": [
    "- Check that the mean values are 0 for the first 5 features in **X_train_scaled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b571f-677e-42c3-859f-8e8a7c2ccd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled... # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b7d39-fa50-4c23-971e-922e617fdfc8",
   "metadata": {},
   "source": [
    "- Check that the standard deviations are 1 for the first 5 features in **X_train_scaled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b5a98-7ebd-42cc-80e1-18e250eb2716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled... # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13591536-3ccc-4cfd-90d6-dca8fcf0b180",
   "metadata": {},
   "source": [
    "## Question 4. Create a model of Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c5fd1-34f0-4ffe-b398-a4d86b648de8",
   "metadata": {},
   "source": [
    "Logistic regression uses an analytical function, called *logistic function* or *sigmoid function*, which has a characteristic S-shape. By optimizing the coefficients of this function (max likelihood or min cross-entropy), it makes it possible to estimate the probability for a sample to belong to this or that class. For example, tumoral versus normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045abab-546b-4600-a1f8-e011f7716713",
   "metadata": {},
   "source": [
    "<img src=\"logistic_regression.png\" alt=\"Logistic regression\" width=\"600\" aling=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631f177-6cf9-4c15-ad14-556bd46c9417",
   "metadata": {},
   "source": [
    "- Create a Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f1dac3-c8cf-4db2-96bd-7f60dafe3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=random_state, penalty='none')\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb636eb-5b88-4c97-bbe9-93f59a7fbb1a",
   "metadata": {},
   "source": [
    "- Train the classifier and calculate its accuracy using `calculate_accuracy` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ab37f-afe4-47c3-a7a5-9b1073ea661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_train, accuracy_test, trained_classifier = calculate_accuracy(classifier, ... , ... , y_train, y_test) # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c979f88-4c04-4076-b2ab-e8f16c87d141",
   "metadata": {},
   "source": [
    "## Question 5. Display a confusion matrix for LR algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e4244-4c56-4319-b51b-835abaac681f",
   "metadata": {},
   "source": [
    "A *confusion matrix* is a table that allows visualisation of the performance of a supervised algorithm. Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871028a5-d435-4f59-9c6d-d6f99a129a22",
   "metadata": {},
   "source": [
    "- Display a confusion maxtrix for LR algorithm **using the test dataset only** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38697f0e-be70-4a4b-a2b6-7bda1a375fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.plot_confusion_matrix(trained_classifier, ... , ...) # to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987e6b0-b312-4204-b513-77c5be4dd0a1",
   "metadata": {},
   "source": [
    "## Question 6. Evaluate the impact of each gene in LR classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18119682-bb5b-4aec-bd50-62903e80c40a",
   "metadata": {},
   "source": [
    "After the training phase, it is possible to know the coefficients $\\beta$ of LR model for each feature (gene). They are available in the `coef_` attribute. The greater is the coefficient $\\beta$ (in absolute value), the greater is the impact of the corresponding gene in the model. By analysing the coefficients $\\beta$ of the trained LR model, we can find the most predictive genes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe734d-bbf9-4cbe-a61f-5e913694e20f",
   "metadata": {},
   "source": [
    "- Display the coefficients $\\beta$ for the first 5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1212576-bc24-47df-950b-e567496895bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame(trained_classifier.coef_[0], index=X_train_scaled.columns, columns=['beta'])\n",
    "coefficients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67803aa-c7c3-4322-a54f-b57990bed02f",
   "metadata": {},
   "source": [
    "- Display the coefficients $\\beta$ as a *barplot* from the smallest to the biggest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3acdc-267f-4c3e-b3d1-9bd31260a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = coefficients.sort_values(by='beta')\n",
    "coefficients.plot.bar(figsize=(15, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b497bcd3-555d-4c10-a656-de6742a5b5fe",
   "metadata": {},
   "source": [
    "- What genes have the most important impact in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a1c26a-dab4-410f-b59e-c160881f2957",
   "metadata": {},
   "source": [
    "- What genes have almost no impact on the prediction? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d307e-9b5a-4d38-bb8a-4127a651b976",
   "metadata": {},
   "source": [
    "- Select the best 3 features mostly impacting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78068ee7-47fa-4fd1-a257-3179d42efad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "coefficients['abs_beta'] = coefficients['beta'].abs() # calculate the absolute values of betas\n",
    "coefficients = coefficients.sort_values(by='abs_beta', ascending=False) # sort by arsolute values\n",
    "top_features = list(coefficients.head(n_features).index) # list of N top features\n",
    "print('Top features of LR:', top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f463cf-5722-451a-9676-71ff575fd04e",
   "metadata": {},
   "source": [
    "## Question 7. Calculate the performance of LR model using 1, 2, ... N top features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d35960-8a3b-455e-afda-ab799dc0bec9",
   "metadata": {},
   "source": [
    "- What does the code below calculate? Execute it and explain the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d325b0-39c2-4720-a816-82201c078a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(top_features)):\n",
    "    selected_features = top_features[0:i+1]\n",
    "    print(selected_features)\n",
    "    accuracy_train, accuracy_test, trained_classifier = calculate_accuracy(classifier, X_train_scaled[selected_features], X_test_scaled[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b606281-d9d6-4877-9211-84e9c07b1a7d",
   "metadata": {},
   "source": [
    "- Do we need all the 60 genes in the model? What do you think? If we can reduce the number of features, how many should we keep? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf62cc-8894-48be-be51-7f7b7afbaf87",
   "metadata": {},
   "source": [
    "## Question 8. Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d6189-2ee1-4d66-8035-0cc0a9991c99",
   "metadata": {},
   "source": [
    "The *AI-Hospital* has developed a new diagnostic tool for colon cancer based on the expression levels of a panel of 3 genes. This tool produced the following measurements for a new patient arrived in the hospital:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa822fb-bbb5-446f-bff6-1bc8dbd0a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = ['RNF43', 'SLC7A5', 'DAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0e971-e1ee-4fef-9f62-ac8fb79e2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patient = {'RNF43': 4.68, 'SLC7A5': 4.10, 'DAO': 7.59}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee8b85-8eca-44a4-8a21-2913b684e76b",
   "metadata": {},
   "source": [
    "- **Does this patient have a colon cancer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450debd2-5c0c-44e7-a2bc-b9f78f7ba953",
   "metadata": {},
   "source": [
    "Hint: To answer this question, train a LR model on the totality of available data **X**. In this case, **X_train** will contain all the samples of **X**. **X_test** will have only one sample corresponding to the new patient. Do not forget to scale the data properly, `fit` on **X_train** only and then  `transform` on both **X_train** and **X_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e42ef-d293-490e-bee2-6c7f963cd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[panel]\n",
    "y_train = y\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040bca8-b880-4c35-bebb-267f9f6baab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame([new_patient], index=['new_patient'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6476807b-f393-4355-a474-7b1d077352d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to write by yourself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
